{"ast":null,"code":"function _slicedToArray(arr, i) { return _arrayWithHoles(arr) || _iterableToArrayLimit(arr, i) || _unsupportedIterableToArray(arr, i) || _nonIterableRest(); }\n\nfunction _nonIterableRest() { throw new TypeError(\"Invalid attempt to destructure non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\"); }\n\nfunction _iterableToArrayLimit(arr, i) { var _i = arr == null ? null : typeof Symbol !== \"undefined\" && arr[Symbol.iterator] || arr[\"@@iterator\"]; if (_i == null) return; var _arr = []; var _n = true; var _d = false; var _s, _e; try { for (_i = _i.call(arr); !(_n = (_s = _i.next()).done); _n = true) { _arr.push(_s.value); if (i && _arr.length === i) break; } } catch (err) { _d = true; _e = err; } finally { try { if (!_n && _i[\"return\"] != null) _i[\"return\"](); } finally { if (_d) throw _e; } } return _arr; }\n\nfunction _arrayWithHoles(arr) { if (Array.isArray(arr)) return arr; }\n\nfunction _createForOfIteratorHelper(o, allowArrayLike) { var it = typeof Symbol !== \"undefined\" && o[Symbol.iterator] || o[\"@@iterator\"]; if (!it) { if (Array.isArray(o) || (it = _unsupportedIterableToArray(o)) || allowArrayLike && o && typeof o.length === \"number\") { if (it) o = it; var i = 0; var F = function () {}; return { s: F, n: function () { if (i >= o.length) return { done: true }; return { done: false, value: o[i++] }; }, e: function (e) { throw e; }, f: F }; } throw new TypeError(\"Invalid attempt to iterate non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\"); } var normalCompletion = true, didErr = false, err; return { s: function () { it = it.call(o); }, n: function () { var step = it.next(); normalCompletion = step.done; return step; }, e: function (e) { didErr = true; err = e; }, f: function () { try { if (!normalCompletion && it.return != null) it.return(); } finally { if (didErr) throw err; } } }; }\n\nfunction _unsupportedIterableToArray(o, minLen) { if (!o) return; if (typeof o === \"string\") return _arrayLikeToArray(o, minLen); var n = Object.prototype.toString.call(o).slice(8, -1); if (n === \"Object\" && o.constructor) n = o.constructor.name; if (n === \"Map\" || n === \"Set\") return Array.from(o); if (n === \"Arguments\" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen); }\n\nfunction _arrayLikeToArray(arr, len) { if (len == null || len > arr.length) len = arr.length; for (var i = 0, arr2 = new Array(len); i < len; i++) arr2[i] = arr[i]; return arr2; }\n\nfunction ownKeys(object, enumerableOnly) { var keys = Object.keys(object); if (Object.getOwnPropertySymbols) { var symbols = Object.getOwnPropertySymbols(object); enumerableOnly && (symbols = symbols.filter(function (sym) { return Object.getOwnPropertyDescriptor(object, sym).enumerable; })), keys.push.apply(keys, symbols); } return keys; }\n\nfunction _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = null != arguments[i] ? arguments[i] : {}; i % 2 ? ownKeys(Object(source), !0).forEach(function (key) { _defineProperty(target, key, source[key]); }) : Object.getOwnPropertyDescriptors ? Object.defineProperties(target, Object.getOwnPropertyDescriptors(source)) : ownKeys(Object(source)).forEach(function (key) { Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key)); }); } return target; }\n\nfunction _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }\n\nimport { copyFromChannel } from '../helpers/copy-from-channel';\nimport { copyToChannel } from '../helpers/copy-to-channel';\nimport { createNestedArrays } from '../helpers/create-nested-arrays';\nimport { getAudioNodeConnections } from '../helpers/get-audio-node-connections';\nimport { getAudioWorkletProcessor } from '../helpers/get-audio-worklet-processor';\nimport { isOwnedByContext } from '../helpers/is-owned-by-context';\n\nconst processBuffer = async (proxy, renderedBuffer, nativeOfflineAudioContext, options, outputChannelCount, processorConstructor, exposeCurrentFrameAndCurrentTime) => {\n  // Ceil the length to the next full render quantum.\n  // Bug #17: Safari does not yet expose the length.\n  const length = renderedBuffer === null ? Math.ceil(proxy.context.length / 128) * 128 : renderedBuffer.length;\n  const numberOfInputChannels = options.channelCount * options.numberOfInputs;\n  const numberOfOutputChannels = outputChannelCount.reduce((sum, value) => sum + value, 0);\n  const processedBuffer = numberOfOutputChannels === 0 ? null : nativeOfflineAudioContext.createBuffer(numberOfOutputChannels, length, nativeOfflineAudioContext.sampleRate);\n\n  if (processorConstructor === undefined) {\n    throw new Error('Missing the processor constructor.');\n  }\n\n  const audioNodeConnections = getAudioNodeConnections(proxy);\n  const audioWorkletProcessor = await getAudioWorkletProcessor(nativeOfflineAudioContext, proxy);\n  const inputs = createNestedArrays(options.numberOfInputs, options.channelCount);\n  const outputs = createNestedArrays(options.numberOfOutputs, outputChannelCount);\n  const parameters = Array.from(proxy.parameters.keys()).reduce((prmtrs, name) => _objectSpread(_objectSpread({}, prmtrs), {}, {\n    [name]: new Float32Array(128)\n  }), {});\n\n  for (let i = 0; i < length; i += 128) {\n    if (options.numberOfInputs > 0 && renderedBuffer !== null) {\n      for (let j = 0; j < options.numberOfInputs; j += 1) {\n        for (let k = 0; k < options.channelCount; k += 1) {\n          copyFromChannel(renderedBuffer, inputs[j], k, k, i);\n        }\n      }\n    }\n\n    if (processorConstructor.parameterDescriptors !== undefined && renderedBuffer !== null) {\n      processorConstructor.parameterDescriptors.forEach((_ref, index) => {\n        let name = _ref.name;\n        copyFromChannel(renderedBuffer, parameters, name, numberOfInputChannels + index, i);\n      });\n    }\n\n    for (let j = 0; j < options.numberOfInputs; j += 1) {\n      for (let k = 0; k < outputChannelCount[j]; k += 1) {\n        // The byteLength will be 0 when the ArrayBuffer was transferred.\n        if (outputs[j][k].byteLength === 0) {\n          outputs[j][k] = new Float32Array(128);\n        }\n      }\n    }\n\n    try {\n      const potentiallyEmptyInputs = inputs.map((input, index) => {\n        if (audioNodeConnections.activeInputs[index].size === 0) {\n          return [];\n        }\n\n        return input;\n      });\n      const activeSourceFlag = exposeCurrentFrameAndCurrentTime(i / nativeOfflineAudioContext.sampleRate, nativeOfflineAudioContext.sampleRate, () => audioWorkletProcessor.process(potentiallyEmptyInputs, outputs, parameters));\n\n      if (processedBuffer !== null) {\n        for (let j = 0, outputChannelSplitterNodeOutput = 0; j < options.numberOfOutputs; j += 1) {\n          for (let k = 0; k < outputChannelCount[j]; k += 1) {\n            copyToChannel(processedBuffer, outputs[j], k, outputChannelSplitterNodeOutput + k, i);\n          }\n\n          outputChannelSplitterNodeOutput += outputChannelCount[j];\n        }\n      }\n\n      if (!activeSourceFlag) {\n        break;\n      }\n    } catch (error) {\n      proxy.dispatchEvent(new ErrorEvent('processorerror', {\n        colno: error.colno,\n        filename: error.filename,\n        lineno: error.lineno,\n        message: error.message\n      }));\n      break;\n    }\n  }\n\n  return processedBuffer;\n};\n\nexport const createAudioWorkletNodeRendererFactory = (connectAudioParam, connectMultipleOutputs, createNativeAudioBufferSourceNode, createNativeChannelMergerNode, createNativeChannelSplitterNode, createNativeConstantSourceNode, createNativeGainNode, deleteUnrenderedAudioWorkletNode, disconnectMultipleOutputs, exposeCurrentFrameAndCurrentTime, getNativeAudioNode, nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor, renderAutomation, renderInputsOfAudioNode, renderNativeOfflineAudioContext) => {\n  return (name, options, processorConstructor) => {\n    const renderedNativeAudioNodes = new WeakMap();\n    let processedBufferPromise = null;\n\n    const createAudioNode = async (proxy, nativeOfflineAudioContext) => {\n      let nativeAudioWorkletNode = getNativeAudioNode(proxy);\n      let nativeOutputNodes = null;\n      const nativeAudioWorkletNodeIsOwnedByContext = isOwnedByContext(nativeAudioWorkletNode, nativeOfflineAudioContext);\n      const outputChannelCount = Array.isArray(options.outputChannelCount) ? options.outputChannelCount : Array.from(options.outputChannelCount); // Bug #61: Only Chrome, Edge & Firefox have an implementation of the AudioWorkletNode yet.\n\n      if (nativeAudioWorkletNodeConstructor === null) {\n        const numberOfOutputChannels = outputChannelCount.reduce((sum, value) => sum + value, 0);\n        const outputChannelSplitterNode = createNativeChannelSplitterNode(nativeOfflineAudioContext, {\n          channelCount: Math.max(1, numberOfOutputChannels),\n          channelCountMode: 'explicit',\n          channelInterpretation: 'discrete',\n          numberOfOutputs: Math.max(1, numberOfOutputChannels)\n        });\n        const outputChannelMergerNodes = [];\n\n        for (let i = 0; i < proxy.numberOfOutputs; i += 1) {\n          outputChannelMergerNodes.push(createNativeChannelMergerNode(nativeOfflineAudioContext, {\n            channelCount: 1,\n            channelCountMode: 'explicit',\n            channelInterpretation: 'speakers',\n            numberOfInputs: outputChannelCount[i]\n          }));\n        }\n\n        const outputGainNode = createNativeGainNode(nativeOfflineAudioContext, {\n          channelCount: options.channelCount,\n          channelCountMode: options.channelCountMode,\n          channelInterpretation: options.channelInterpretation,\n          gain: 1\n        });\n        outputGainNode.connect = connectMultipleOutputs.bind(null, outputChannelMergerNodes);\n        outputGainNode.disconnect = disconnectMultipleOutputs.bind(null, outputChannelMergerNodes);\n        nativeOutputNodes = [outputChannelSplitterNode, outputChannelMergerNodes, outputGainNode];\n      } else if (!nativeAudioWorkletNodeIsOwnedByContext) {\n        nativeAudioWorkletNode = new nativeAudioWorkletNodeConstructor(nativeOfflineAudioContext, name);\n      }\n\n      renderedNativeAudioNodes.set(nativeOfflineAudioContext, nativeOutputNodes === null ? nativeAudioWorkletNode : nativeOutputNodes[2]);\n\n      if (nativeOutputNodes !== null) {\n        if (processedBufferPromise === null) {\n          if (processorConstructor === undefined) {\n            throw new Error('Missing the processor constructor.');\n          }\n\n          if (nativeOfflineAudioContextConstructor === null) {\n            throw new Error('Missing the native OfflineAudioContext constructor.');\n          } // Bug #47: The AudioDestinationNode in Safari gets not initialized correctly.\n\n\n          const numberOfInputChannels = proxy.channelCount * proxy.numberOfInputs;\n          const numberOfParameters = processorConstructor.parameterDescriptors === undefined ? 0 : processorConstructor.parameterDescriptors.length;\n          const numberOfChannels = numberOfInputChannels + numberOfParameters;\n\n          const renderBuffer = async () => {\n            const partialOfflineAudioContext = new nativeOfflineAudioContextConstructor(numberOfChannels, // Ceil the length to the next full render quantum.\n            // Bug #17: Safari does not yet expose the length.\n            Math.ceil(proxy.context.length / 128) * 128, nativeOfflineAudioContext.sampleRate);\n            const gainNodes = [];\n            const inputChannelSplitterNodes = [];\n\n            for (let i = 0; i < options.numberOfInputs; i += 1) {\n              gainNodes.push(createNativeGainNode(partialOfflineAudioContext, {\n                channelCount: options.channelCount,\n                channelCountMode: options.channelCountMode,\n                channelInterpretation: options.channelInterpretation,\n                gain: 1\n              }));\n              inputChannelSplitterNodes.push(createNativeChannelSplitterNode(partialOfflineAudioContext, {\n                channelCount: options.channelCount,\n                channelCountMode: 'explicit',\n                channelInterpretation: 'discrete',\n                numberOfOutputs: options.channelCount\n              }));\n            }\n\n            const constantSourceNodes = await Promise.all(Array.from(proxy.parameters.values()).map(async audioParam => {\n              const constantSourceNode = createNativeConstantSourceNode(partialOfflineAudioContext, {\n                channelCount: 1,\n                channelCountMode: 'explicit',\n                channelInterpretation: 'discrete',\n                offset: audioParam.value\n              });\n              await renderAutomation(partialOfflineAudioContext, audioParam, constantSourceNode.offset);\n              return constantSourceNode;\n            }));\n            const inputChannelMergerNode = createNativeChannelMergerNode(partialOfflineAudioContext, {\n              channelCount: 1,\n              channelCountMode: 'explicit',\n              channelInterpretation: 'speakers',\n              numberOfInputs: Math.max(1, numberOfInputChannels + numberOfParameters)\n            });\n\n            for (let i = 0; i < options.numberOfInputs; i += 1) {\n              gainNodes[i].connect(inputChannelSplitterNodes[i]);\n\n              for (let j = 0; j < options.channelCount; j += 1) {\n                inputChannelSplitterNodes[i].connect(inputChannelMergerNode, j, i * options.channelCount + j);\n              }\n            }\n\n            var _iterator = _createForOfIteratorHelper(constantSourceNodes.entries()),\n                _step;\n\n            try {\n              for (_iterator.s(); !(_step = _iterator.n()).done;) {\n                const _step$value = _slicedToArray(_step.value, 2),\n                      index = _step$value[0],\n                      constantSourceNode = _step$value[1];\n\n                constantSourceNode.connect(inputChannelMergerNode, 0, numberOfInputChannels + index);\n                constantSourceNode.start(0);\n              }\n            } catch (err) {\n              _iterator.e(err);\n            } finally {\n              _iterator.f();\n            }\n\n            inputChannelMergerNode.connect(partialOfflineAudioContext.destination);\n            await Promise.all(gainNodes.map(gainNode => renderInputsOfAudioNode(proxy, partialOfflineAudioContext, gainNode)));\n            return renderNativeOfflineAudioContext(partialOfflineAudioContext);\n          };\n\n          processedBufferPromise = processBuffer(proxy, numberOfChannels === 0 ? null : await renderBuffer(), nativeOfflineAudioContext, options, outputChannelCount, processorConstructor, exposeCurrentFrameAndCurrentTime);\n        }\n\n        const processedBuffer = await processedBufferPromise;\n        const audioBufferSourceNode = createNativeAudioBufferSourceNode(nativeOfflineAudioContext, {\n          buffer: null,\n          channelCount: 2,\n          channelCountMode: 'max',\n          channelInterpretation: 'speakers',\n          loop: false,\n          loopEnd: 0,\n          loopStart: 0,\n          playbackRate: 1\n        });\n\n        const _nativeOutputNodes = nativeOutputNodes,\n              _nativeOutputNodes2 = _slicedToArray(_nativeOutputNodes, 3),\n              outputChannelSplitterNode = _nativeOutputNodes2[0],\n              outputChannelMergerNodes = _nativeOutputNodes2[1],\n              outputGainNode = _nativeOutputNodes2[2];\n\n        if (processedBuffer !== null) {\n          audioBufferSourceNode.buffer = processedBuffer;\n          audioBufferSourceNode.start(0);\n        }\n\n        audioBufferSourceNode.connect(outputChannelSplitterNode);\n\n        for (let i = 0, outputChannelSplitterNodeOutput = 0; i < proxy.numberOfOutputs; i += 1) {\n          const outputChannelMergerNode = outputChannelMergerNodes[i];\n\n          for (let j = 0; j < outputChannelCount[i]; j += 1) {\n            outputChannelSplitterNode.connect(outputChannelMergerNode, outputChannelSplitterNodeOutput + j, j);\n          }\n\n          outputChannelSplitterNodeOutput += outputChannelCount[i];\n        }\n\n        return outputGainNode;\n      }\n\n      if (!nativeAudioWorkletNodeIsOwnedByContext) {\n        var _iterator2 = _createForOfIteratorHelper(proxy.parameters.entries()),\n            _step2;\n\n        try {\n          for (_iterator2.s(); !(_step2 = _iterator2.n()).done;) {\n            const _step2$value = _slicedToArray(_step2.value, 2),\n                  nm = _step2$value[0],\n                  audioParam = _step2$value[1];\n\n            await renderAutomation(nativeOfflineAudioContext, audioParam, // @todo The definition that TypeScript uses of the AudioParamMap is lacking many methods.\n            nativeAudioWorkletNode.parameters.get(nm));\n          }\n        } catch (err) {\n          _iterator2.e(err);\n        } finally {\n          _iterator2.f();\n        }\n      } else {\n        var _iterator3 = _createForOfIteratorHelper(proxy.parameters.entries()),\n            _step3;\n\n        try {\n          for (_iterator3.s(); !(_step3 = _iterator3.n()).done;) {\n            const _step3$value = _slicedToArray(_step3.value, 2),\n                  nm = _step3$value[0],\n                  audioParam = _step3$value[1];\n\n            await connectAudioParam(nativeOfflineAudioContext, audioParam, // @todo The definition that TypeScript uses of the AudioParamMap is lacking many methods.\n            nativeAudioWorkletNode.parameters.get(nm));\n          }\n        } catch (err) {\n          _iterator3.e(err);\n        } finally {\n          _iterator3.f();\n        }\n      }\n\n      await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioWorkletNode);\n      return nativeAudioWorkletNode;\n    };\n\n    return {\n      render(proxy, nativeOfflineAudioContext) {\n        deleteUnrenderedAudioWorkletNode(nativeOfflineAudioContext, proxy);\n        const renderedNativeAudioWorkletNodeOrGainNode = renderedNativeAudioNodes.get(nativeOfflineAudioContext);\n\n        if (renderedNativeAudioWorkletNodeOrGainNode !== undefined) {\n          return Promise.resolve(renderedNativeAudioWorkletNodeOrGainNode);\n        }\n\n        return createAudioNode(proxy, nativeOfflineAudioContext);\n      }\n\n    };\n  };\n};","map":null,"metadata":{},"sourceType":"module"}